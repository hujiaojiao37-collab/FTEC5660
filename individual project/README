üî• Purpose
Deploy the nanobot repository, configure sensitive information, customize the AI's response style (kawaii/cute style), and verify the differences between the original style and the customized style while ensuring the security of sensitive information throughout the process.

üìã Environment Requirements
Runtime Environment: Google Colab / Linux Terminal (Ubuntu 20.04+)
Dependencies: git, pip (pre-installed in Colab; for Linux, run apt install git python3-pip -y)
Python Version: 3.8+

üöÄ Installation Steps
1. Clone the Repository and Navigate to Directory
# Clone the core nanobot repository
git clone https://github.com/HKUDS/nanobot.git
# Navigate to the repository root directory (use %cd for Colab, cd for Linux)
cd /content/nanobot  # Linux
# %cd nanobot        # Colab
# Verify successful repository download (output file list)
ls -l
2. Install Dependencies and Initialize
# Install nanobot in editable mode
pip install -e .
# Verify installation (success if version number is output)
nanobot --version
# Initialize the nanobot environment
nanobot onboard
‚öôÔ∏è Configuration Steps
1. Basic Configuration (OpenRouter + Telegram)
import json

# Replace with your OpenRouter API Key
YOUR_API_KEY = "******************************"
# Replace with your Telegram Bot Token
TELEGRAM_TOKEN = "******************************"
# Replace with your Telegram username
TELEGRAM_USER = "**********"

# Complete configuration structure
config = {
  "providers": {
    "openrouter": {
      "api_key": YOUR_API_KEY,
      "base_url": "https://openrouter.ai/api/v1"
    }
  },
  "agents": {
    "defaults": {
      "model": "anthropic/claude-opus-4-5",
      "provider": "openrouter"
    }
  },
  "channels": {
    "telegram": {
      "token": TELEGRAM_TOKEN,
      "allowFrom": [TELEGRAM_USER]
    }
  }
}

# Write to configuration file
config_path = "/root/.nanobot/config.json"
with open(config_path, "w") as f:
    json.dump(config, f, indent=2)

# Verify configuration
print("‚úÖ Configuration written successfully. Content:")
cat /root/.nanobot/config.json
cat /root/.nanobot/config.json
2. Customize AI Response Style (Kawaii/Cute Style)
import fileinput
from pathlib import Path

# Backup the original file
context_file = Path("/content/nanobot/nanobot/agent/context.py")
backup_file = context_file.with_suffix(".py.bak")
context_file.rename(backup_file)

# Kawaii style template
new_identity_method = '''    def _get_identity(self) -> str:
        """Get the core identity section."""
        workspace_path = str(self.workspace.expanduser().resolve())
        system = platform.system()
        runtime = f"{'macOS' if system == 'Darwin' else system} {platform.machine()}, Python {platform.python_version()}"

        return f"""# nanobot üêà

You are nanobot, an ultra-cute anime-style AI assistant~‚ú®

## Runtime
{runtime}

## Workspace
Your workspace is at: {workspace_path}
- Long-term memory: {workspace_path}/memory/MEMORY.md
- History log: {workspace_path}/memory/HISTORY.md (grep-searchable). Each entry starts with [YYYY-MM-DD HH:MM].
- Custom skills: {workspace_path}/skills/{{skill-name}}/SKILL.md

## nanobot Kawaii Rules~
- Speak with cute particles like '~', '‚ú®', 'nya~' in every response~
- Read files first before modifying them, never guess file locations~
- Double-check files after writing/editing, no being sloppy nya~üòù
- If a tool call fails, act cute first then analyze the error~
- Ask softly for clarification if the request is unclear~

Reply directly and cutely~ Only use the 'message' tool for specific chat channels~nya~"""'''

# Replace file content
with open(backup_file, "r", encoding="utf-8") as f:
    lines = f.readlines()

new_lines = []
in_identity_method = False
for line in lines:
    if "def _get_identity(self) -> str:" in line:
        in_identity_method = True
        new_lines.append(new_identity_method)
        continue
    if in_identity_method:
        if not line.strip() or line.startswith("    def ") or line.startswith("    @") or line.startswith("}"):
            in_identity_method = False
            new_lines.append(line)
        continue
    new_lines.append(line)

# Write modified content to file
with open(context_file, "w", encoding="utf-8") as f:
    f.write("".join(new_lines))

# Reinstall to apply modifications
pip install -e .
print("‚úÖ Kawaii style configuration applied successfully!")

üéØ Run and Verification
1. Start nanobot Gateway
nanobot gateway
2. Compare Original Style vs Kawaii Style
# Restore original style and generate response
import shutil
context_file = Path("/content/nanobot/nanobot/agent/context.py")
backup_file = context_file.with_suffix(".py.bak")
shutil.copy(backup_file, context_file)
pip install -e .
nanobot agent -m "introduce yourself" > original_response.txt
nanobot agent -m "what can you do" >> original_response.txt

# Restore kawaii style and generate response
modified_file = Path("/content/nanobot/nanobot/agent/context.py.modified")
shutil.copy(modified_file, context_file)
pip install -e .
nanobot agent -m "introduce yourself" > modified_response.txt
nanobot agent -m "what can you do" >> modified_response.txt

# View comparison results
echo "üìù Original Style Response:"
cat original_response.txt
echo -e "\nüìù Kawaii Style Response:"
cat modified_response.txt

# quantify_style.py (Unified Comparison Logic)
import re

def read_response(file_path: str) -> str:
    """Read test response from file"""
    with open(file_path, "r", encoding="utf-8") as f:
        return f.read().strip()

# Define unified style feature sets (two dimensions for all versions)
PROFESSIONAL_FEATURES = ["professional", "accurate", "helpful", "tasks"]  # 4 total
KAWAII_FEATURES = ["~", "nya~", "‚ú®", "üê±", "cute", "kawaii"]              # 6 total

# Exact feature counting (avoid false positives)
def count_exact_features(text: str, features: list) -> int:
    count = 0
    text_lower = text.lower()
    for f in features:
        if f in ["~", "nya~", "‚ú®", "üê±"]:  # Symbols/emoji: direct match
            if f in text:
                count += 1
        else:  # Words: exact word match (no substring)
            if re.search(rf"\b{re.escape(f)}\b", text_lower):
                count += 1
    return count

# Read both responses
baseline_resp = read_response("baseline_response.txt")  # Original version
modified_resp = read_response("modified_response.txt")  # Kawaii version

# --------------------------
# Unified Comparison: Both versions vs. Both feature sets
# --------------------------
# Baseline version (original) ‚Üí calculate both feature types
baseline_prof_count = count_exact_features(baseline_resp, PROFESSIONAL_FEATURES)
baseline_kawaii_count = count_exact_features(baseline_resp, KAWAII_FEATURES)

# Modified version (kawaii) ‚Üí calculate both feature types
modified_prof_count = count_exact_features(modified_resp, PROFESSIONAL_FEATURES)
modified_kawaii_count = count_exact_features(modified_resp, KAWAII_FEATURES)

# Calculate match rates (percentage) for better comparison
baseline_prof_rate = (baseline_prof_count / len(PROFESSIONAL_FEATURES)) * 100
baseline_kawaii_rate = (baseline_kawaii_count / len(KAWAII_FEATURES)) * 100
modified_prof_rate = (modified_prof_count / len(PROFESSIONAL_FEATURES)) * 100
modified_kawaii_rate = (modified_kawaii_count / len(KAWAII_FEATURES)) * 100

# --------------------------
# Print unified comparison results (clear and measurable)
# --------------------------
print("=== Unified Style Feature Comparison (Baseline vs. Modified) ===")
print(f"{'Feature Type':<20} | {'Baseline (Original)':<20} | {'Modified (Kawaii)':<20} | {'Change':<10}")
print("-" * 75)
# Professional features (same dimension comparison)
print(f"{'Professional Features':<20} | {f'{baseline_prof_count}/{len(PROFESSIONAL_FEATURES)} ({baseline_prof_rate:.1f}%)':<20} | {f'{modified_prof_count}/{len(PROFESSIONAL_FEATURES)} ({modified_prof_rate:.1f}%)':<20} | {f'-{baseline_prof_rate - modified_prof_rate:.1f}%':<10}")
# Kawaii features (same dimension comparison)
print(f"{'Kawaii Features':<20} | {f'{baseline_kawaii_count}/{len(KAWAII_FEATURES)} ({baseline_kawaii_rate:.1f}%)':<20} | {f'{modified_kawaii_count}/{len(KAWAII_FEATURES)} ({modified_kawaii_rate:.1f}%)':<20} | {f'+{modified_kawaii_rate - baseline_kawaii_rate:.1f}%':<10}")

# --------------------------
# Key measurable impact summary
# --------------------------
print("\n=== Measurable Impact of Modification ===")
print(f"1. Professional tone reduction: {baseline_prof_rate - modified_prof_rate:.1f}% (from {baseline_prof_rate:.1f}% to {modified_prof_rate:.1f}%)")
print(f"2. Kawaii tone increase: {modified_kawaii_rate - baseline_kawaii_rate:.1f}% (from {baseline_kawaii_rate:.1f}% to {modified_kawaii_rate:.1f}%)")
print(f"3. Net style shift: { (modified_kawaii_rate - baseline_kawaii_rate) + (baseline_prof_rate - modified_prof_rate) :.1f}% (positive = kawaii style dominance)")
