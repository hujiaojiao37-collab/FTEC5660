# -*- coding: utf-8 -*-
"""„Äånan.ipynb„ÄçÁöÑÂâØÊú¨

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bWRI44bNb8GTg-fID8MJN4wrHCKNueIt
"""

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/HKUDS/nanobot.git
# %cd nanobot
!ls -l

# Commented out IPython magic to ensure Python compatibility.
# 1. Make sure in the nanobot directory
# %cd /content/nanobot
# 2. Reinstall
!pip install -e .
# 3. Verify if the command is available
!nanobot --version
# 4. Reinitialize
!nanobot onboard

import json
# Correct Configuration Structure
config = {
  "providers": {
    "openrouter": {
      "api_key": "sk-or-v1-xxxx"
,
    }
  },
  "agents": {
    "defaults": {
      "model": "anthropic/claude-opus-4-5",
      "provider": "openrouter"
    }
  }
}

# Write configuration file
config_path = "/root/.nanobot/config.json"
with open(config_path, "w") as f:
    json.dump(config, f, indent=2)

# Verify the configuration file content
print("Current configuration file content:")
!cat /root/.nanobot/config.json

config_path = "/root/.nanobot/config.json"
with open(config_path, "w") as f:
    json.dump(config, f, indent=2)

!cat /root/.nanobot/config.json

import json


YOUR_API_KEY = "sk-or-v1-xxxx"


config = {
  "providers": {
    "openrouter": {
      "api_key": YOUR_API_KEY,
      "base_url": "https://openrouter.ai/api/v1"
    }
  },
  "agents": {
    "defaults": {
      "model": "anthropic/claude-opus-4-5",
      "provider": "openrouter"
    }
  },
  "channels": {
    "telegram": {
      "token": "telegram token",
      "allowFrom": ["your telegram name"]
    }
  }
}


config_path = "/root/.nanobot/config.json"
with open(config_path, "w") as f:
    json.dump(config, f, indent=2)


print("The configuration file has been updated, and the content is as follows:")
!cat /root/.nanobot/config.json

!nanobot agent

!nanobot gateway

# Commented out IPython magic to ensure Python compatibility.
import fileinput
from pathlib import Path
import platform  # Add missing import for platform module

# Locate the core context.py file
context_file = Path("/content/nanobot/nanobot/agent/context.py")

# Define the kawaii-style identity method (fixed string closure)
new_identity_method = '''    def _get_identity(self) -> str:
        """Get the core identity section."""
        workspace_path = str(self.workspace.expanduser().resolve())
        system = platform.system()
        runtime = f"{'macOS' if system == 'Darwin' else system} {platform.machine()}, Python {platform.python_version()}"

        return f"""# nanobot üêà

You are nanobot, an ultra-cute anime-style AI assistant~‚ú®

## Runtime
{runtime}

## Workspace
Your workspace is at: {workspace_path}
- Long-term memory: {workspace_path}/memory/MEMORY.md
- History log: {workspace_path}/memory/HISTORY.md (grep-searchable). Each entry starts with [YYYY-MM-DD HH:MM].
- Custom skills: {workspace_path}/skills/{{skill-name}}/SKILL.md

## nanobot Kawaii Rules~
- Speak with cute particles like '~', '‚ú®', 'nya~' in every response
- Read files first before modifying them, never guess file locations
- Double-check files after writing/editing
- If a tool call fails, act cute first then analyze the error
- Ask softly for clarification if the request is unclear

Reply directly and cutely Only use the 'message' tool for specific chat channels"""'''  # Fixed: Add closing ''' here

# Backup original file with error handling (avoid duplicate backup error)
backup_file = context_file.with_suffix(".py.bak")
if not backup_file.exists():  # Only backup if file doesn't exist
    context_file.rename(backup_file)

# Read original file content
with open(backup_file, "r", encoding="utf-8") as f:
    lines = f.readlines()

# Replace _get_identity method with kawaii version
new_lines = []
in_identity_method = False
for line in lines:
    if "def _get_identity(self) -> str:" in line:
        in_identity_method = True
        new_lines.append(new_identity_method)
        continue
    if in_identity_method:
        # Exit condition: stop skipping lines when new method/empty line is found
        if not line.strip() or line.startswith("    def ") or line.startswith("    @") or line.startswith("}"):
            in_identity_method = False
            new_lines.append(line)
        continue
    new_lines.append(line)

# Write modified content back to context.py
with open(context_file, "w", encoding="utf-8") as f:
    f.write("".join(new_lines))

# Switch to nanobot directory and reinstall to apply changes
# %cd /content/nanobot
!pip install -e .

# Success message
print("‚úÖ Modified only core style rules (Workspace kept original)")

# Test with English question to verify style
!nanobot agent

import json

config_path = "/root/.nanobot/config.json"

# ËØªÂèñÈÖçÁΩÆÊñá‰ª∂
with open(config_path, "r") as f:
    config = json.load(f)

# Á°Æ‰øù agents.defaults ËäÇÁÇπÂ≠òÂú®
if "agents" not in config:
    config["agents"] = {}
if "defaults" not in config["agents"]:
    config["agents"]["defaults"] = {}

# Êç¢ÂõûÂéüÊ®°ÂûãÔºàdeepseek/deepseek-chatÔºâ
config["agents"]["defaults"]["model"] = "anthropic/claude-opus-4-5"
# ÂêåÊó∂‰øùÁïô 1000 tokens ÈôêÂà∂ÔºàÈÅøÂÖçÈ¢ùÂ∫¶ÈóÆÈ¢òÔºâ


# ‰øùÂ≠òÈÖçÁΩÆ
with open(config_path, "w") as f:
    json.dump(config, f, indent=2)

print("‚úÖ Â∑≤ÊàêÂäüÊç¢ÂõûÂéüÊ®°Âûã deepseek/deepseek-chat")
print("üìù ÂΩìÂâçÈÖçÁΩÆÔºö")
!cat /root/.nanobot/config.json | grep -A 5 "defaults"

# Commented out IPython magic to ensure Python compatibility.
import shutil
from pathlib import Path

# Restore the original version of context.py
context_file = Path("/content/nanobot/nanobot/agent/context.py")
backup_file = context_file.with_suffix(".py.bak")

# First back up the currently modified files (to avoid loss)
shutil.copy(context_file, context_file.with_suffix(".py.modified"))

# Restore original file
shutil.copy(backup_file, context_file)

# Reinstall to take effect
# %cd /content/nanobot
!pip install -e .

# Generate the original version of the answer (save to file)
!nanobot agent -m "introduce yourself" > original_response.txt
!nanobot agent -m "what can you do" >> original_response.txt

print("‚úÖ The original version of the response has been generated and saved to original_response.txt")
print("üìù Original version response content:")
!cat original_response.txt

# Restored and modified context.py file
modified_file = Path("/content/nanobot/nanobot/agent/context.py.modified")
context_file = Path("/content/nanobot/nanobot/agent/context.py")
shutil.copy(modified_file, context_file)

# Reinstall to take effect
!pip install -e .

# Generate the modified answer (save to file)
!nanobot agent -m "introduce yourself" > modified_response.txt
!nanobot agent -m "what can you do" >> modified_response.txt

print("‚úÖ The revised version of the response has been generated and saved to modified_response.txt")
print("üìù Content of the revised version's response:")
!cat modified_response.txt

# quantify_style.py (Unified Comparison Logic)
import re

def read_response(file_path: str) -> str:
    """Read test response from file"""
    with open(file_path, "r", encoding="utf-8") as f:
        return f.read().strip()

# Define unified style feature sets (two dimensions for all versions)
PROFESSIONAL_FEATURES = ["professional", "accurate", "helpful", "tasks"]  # 4 total
KAWAII_FEATURES = ["~", "nya~", "‚ú®", "üê±", "cute", "kawaii"]              # 6 total

# Exact feature counting (avoid false positives)
def count_exact_features(text: str, features: list) -> int:
    count = 0
    text_lower = text.lower()
    for f in features:
        if f in ["~", "nya~", "‚ú®", "üê±"]:  # Symbols/emoji: direct match
            if f in text:
                count += 1
        else:  # Words: exact word match (no substring)
            if re.search(rf"\b{re.escape(f)}\b", text_lower):
                count += 1
    return count

# Read both responses
baseline_resp = read_response("original_response.txt")  # Original version
modified_resp = read_response("modified_response.txt")  # Kawaii version

# --------------------------
# Unified Comparison: Both versions vs. Both feature sets
# --------------------------
# Baseline version (original) ‚Üí calculate both feature types
baseline_prof_count = count_exact_features(baseline_resp, PROFESSIONAL_FEATURES)
baseline_kawaii_count = count_exact_features(baseline_resp, KAWAII_FEATURES)

# Modified version (kawaii) ‚Üí calculate both feature types
modified_prof_count = count_exact_features(modified_resp, PROFESSIONAL_FEATURES)
modified_kawaii_count = count_exact_features(modified_resp, KAWAII_FEATURES)

# Calculate match rates (percentage) for better comparison
baseline_prof_rate = (baseline_prof_count / len(PROFESSIONAL_FEATURES)) * 100
baseline_kawaii_rate = (baseline_kawaii_count / len(KAWAII_FEATURES)) * 100
modified_prof_rate = (modified_prof_count / len(PROFESSIONAL_FEATURES)) * 100
modified_kawaii_rate = (modified_kawaii_count / len(KAWAII_FEATURES)) * 100

# --------------------------
# Print unified comparison results (clear and measurable)
# --------------------------
print("=== Unified Style Feature Comparison (Baseline vs. Modified) ===")
print(f"{'Feature Type':<20} | {'Baseline (Original)':<20} | {'Modified (Kawaii)':<20} | {'Change':<10}")
print("-" * 75)
# Professional features (same dimension comparison)
print(f"{'Professional Features':<20} | {f'{baseline_prof_count}/{len(PROFESSIONAL_FEATURES)} ({baseline_prof_rate:.1f}%)':<20} | {f'{modified_prof_count}/{len(PROFESSIONAL_FEATURES)} ({modified_prof_rate:.1f}%)':<20} | {f'-{baseline_prof_rate - modified_prof_rate:.1f}%':<10}")
# Kawaii features (same dimension comparison)
print(f"{'Kawaii Features':<20} | {f'{baseline_kawaii_count}/{len(KAWAII_FEATURES)} ({baseline_kawaii_rate:.1f}%)':<20} | {f'{modified_kawaii_count}/{len(KAWAII_FEATURES)} ({modified_kawaii_rate:.1f}%)':<20} | {f'+{modified_kawaii_rate - baseline_kawaii_rate:.1f}%':<10}")

# --------------------------
# Key measurable impact summary
# --------------------------
print("\n=== Measurable Impact of Modification ===")
print(f"1. Professional tone reduction: {baseline_prof_rate - modified_prof_rate:.1f}% (from {baseline_prof_rate:.1f}% to {modified_prof_rate:.1f}%)")
print(f"2. Kawaii tone increase: {modified_kawaii_rate - baseline_kawaii_rate:.1f}% (from {baseline_kawaii_rate:.1f}% to {modified_kawaii_rate:.1f}%)")
print(f"3. Net style shift: { (modified_kawaii_rate - baseline_kawaii_rate) + (baseline_prof_rate - modified_prof_rate) :.1f}% (positive = kawaii style dominance)")